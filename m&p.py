# -*- coding: utf-8 -*-
"""M&P.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-LXQAW72tUywyB--5WXeKeS1EHb-cDeR
"""

!pip install pandas scikit-learn matplotlib seaborn

import pandas as pd
import numpy as np
import re
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.gaussian_process import GaussianProcessRegressor, GaussianProcessClassifier
from sklearn.gaussian_process.kernels import RBF
from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import RocCurveDisplay
import warnings

# Ignore ConvergenceWarnings
warnings.filterwarnings("ignore")

# 1. Data Loading and Initial Inspection
data = pd.read_csv('amazon_product.csv')

# Display the first few rows of the DataFrame
print("First 5 rows of the data:\n", data.head())

# Get information about the DataFrame
print("\nDataframe info:\n", data.info())

# Get descriptive statistics of the DataFrame
print("\nDataframe description:\n", data.describe())

# 2. Data Preprocessing
# Handle missing values
# Check for missing values in each column
print("\nMissing values per column:\n", data.isnull().sum())

# Visualization of missing values
plt.figure(figsize=(12, 6))
sns.heatmap(data.isnull(), cbar=False, cmap='viridis')
plt.title('Missing Values Heatmap')
plt.show()

# Clean currency symbols from price columns and convert to numeric
def clean_price(price_str):
    if isinstance(price_str, str):
        # Remove all non-numeric characters except the decimal point
        cleaned_str = re.sub(r'[^\d\.]', '', price_str)
        try:
            return float(cleaned_str)
        except ValueError:
            return np.nan
    return price_str

for col in ['product_price', 'product_original_price', 'product_minimum_offer_price']:
    data[col] = data[col].apply(clean_price)

# Impute missing numerical values with the mean
for col in ['product_price', 'product_original_price', 'product_star_rating', 'product_num_ratings', 'product_minimum_offer_price']:
    data[col] = data[col].fillna(data[col].mean())

# Impute missing categorical values with the mode
for col in ['currency', 'delivery', 'product_availability']:
    data[col] = data[col].fillna(data[col].mode()[0])

# Convert data types
# Clean and convert 'sales_volume' to numeric
data['sales_volume'] = data['sales_volume'].astype(str)  # Ensure it's treated as a string
data['sales_volume'] = data['sales_volume'].str.replace(r'[K+ bought in past month,]', '', regex=True)
data['sales_volume'] = data['sales_volume'].str.replace(r'[List:]', '', regex=True)

# Replace empty strings with NaN for proper conversion
data['sales_volume'] = data['sales_volume'].replace('', np.nan)

# Fill NaN values with 0 or a more appropriate value based on your data
data['sales_volume'] = data['sales_volume'].fillna(0)  # Filling with 0

# Now convert to numeric
data['sales_volume'] = pd.to_numeric(data['sales_volume'], errors='coerce')
data['sales_volume'] = data['sales_volume'].apply(lambda x: x * 1000 if x < 100 else x)

# Convert necessary columns to appropriate types
data['product_price'] = pd.to_numeric(data['product_price'], errors='coerce')
data['product_original_price'] = pd.to_numeric(data['product_original_price'], errors='coerce')
data['product_star_rating'] = pd.to_numeric(data['product_star_rating'], errors='coerce')
data['product_num_ratings'] = pd.to_numeric(data['product_num_ratings'], errors='coerce')

# Feature Engineering
# Create 'price_discount' feature
data['price_discount'] = data['product_original_price'] - data['product_price']
data['price_discount'] = data['price_discount'].fillna(0)

# Extract delivery time from 'delivery'
def extract_delivery_time(delivery_string):
    if isinstance(delivery_string, str):
        match = re.search(r'(\w+), Aug (\d+)', delivery_string)
        if match:
            return int(match.group(2))  # Extract the day
    return np.nan  # Return NaN if extraction fails

data['delivery_time'] = data['delivery'].apply(extract_delivery_time)
data['delivery_time'] = data['delivery_time'].fillna(data['delivery_time'].mean())

# Convert boolean-like columns to boolean type
bool_like_cols = ['is_best_seller', 'is_amazon_choice', 'is_prime', 'climate_pledge_friendly', 'has_variations']
for col in bool_like_cols:
    if data[col].dtype == 'object':  # Check if the column is of type 'object' (string)
        data[col] = data[col].str.lower() == 'true'  # Convert string 'true' to boolean True

# One-Hot Encoding for categorical features
data = pd.get_dummies(data, columns=['currency', 'is_best_seller', 'is_amazon_choice', 'is_prime', 'climate_pledge_friendly'])

# Define numerical and categorical features
numerical_features = ['product_price', 'product_original_price', 'product_star_rating', 'product_num_ratings', 'price_discount', 'delivery_time']

# Handle remaining missing values after feature engineering
for col in numerical_features:
    if data[col].isnull().any():
        data[col] = data[col].fillna(data[col].mean())

# Data Scaling for numerical features
scaler = StandardScaler()
data[numerical_features] = scaler.fit_transform(data[numerical_features])

# After preprocessing, explicitly drop rows where 'sales_volume' is NaN
data = data.dropna(subset=['sales_volume'])

# Display the preprocessed data
print("\nPreprocessed Data:\n", data.head())

# Distribution of 'sales_volume' after cleaning
plt.figure(figsize=(10, 6))
sns.histplot(data['sales_volume'], kde=True)
plt.title('Distribution of Sales Volume after Cleaning')
plt.xlabel('Sales Volume')
plt.ylabel('Frequency')
plt.show()

# Correlation heatmap for numerical features
plt.figure(figsize=(12, 10))
sns.heatmap(data[numerical_features].corr(), annot=True, cmap='coolwarm')
plt.title('Correlation Heatmap of Numerical Features')
plt.show()

# Scatter plot of 'product_price' vs 'sales_volume'
plt.figure(figsize=(10, 6))
plt.scatter(data['product_price'], data['sales_volume'], alpha=0.5)
plt.title('Scatter Plot of Product Price vs Sales Volume')
plt.xlabel('Product Price')
plt.ylabel('Sales Volume')
plt.show()

# 3. Gaussian Process Regression
# Feature Selection
# Choose input features for regression
regression_features = ['product_price', 'product_star_rating', 'product_num_ratings', 'price_discount', 'delivery_time']

# Prepare data for regression
X_regression = data[regression_features]
y_regression = data['sales_volume']

# Split the data into training and testing sets
X_regression_train, X_regression_test, y_regression_train, y_regression_test = train_test_split(X_regression, y_regression, test_size=0.2, random_state=42)

# Define a kernel
kernel = RBF(length_scale=1.0, length_scale_bounds=(1e-1, 10.0))

# Create a GaussianProcessRegressor object with the chosen kernel
gp_regressor = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10)

# Train the model
gp_regressor.fit(X_regression_train, y_regression_train)

# Prediction and Evaluation
# Predict sales_volume on the testing set
y_regression_pred, sigma = gp_regressor.predict(X_regression_test, return_std=True)

# Evaluate the model
mse = mean_squared_error(y_regression_test, y_regression_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_regression_test, y_regression_pred)

print("\nGaussian Process Regression Results:")
print("Mean Squared Error:", mse)
print("Root Mean Squared Error:", rmse)
print("R-squared:", r2)

# Regression Plots

# 1. Scatter plot of Actual vs. Predicted Values with Confidence Intervals
plt.figure(figsize=(10, 6))
plt.scatter(y_regression_test, y_regression_pred, alpha=0.5, label='Predicted Values')
plt.errorbar(y_regression_test, y_regression_pred, yerr=sigma, fmt='o', alpha=0.3, label='Confidence Interval')
plt.xlabel("Actual Sales Volume")
plt.ylabel("Predicted Sales Volume")
plt.title("Gaussian Process Regression: Actual vs. Predicted with Confidence Intervals")
plt.legend()
plt.show()

# 2. Residual Plot
residuals = y_regression_test - y_regression_pred
plt.figure(figsize=(10, 6))
plt.scatter(y_regression_pred, residuals, alpha=0.5)
plt.hlines(y=0, xmin=y_regression_pred.min(), xmax=y_regression_pred.max(), colors='red', linestyles='--')
plt.xlabel("Predicted Sales Volume")
plt.ylabel("Residuals (Actual - Predicted)")
plt.title("Gaussian Process Regression: Residual Plot")
plt.show()

# 3. Distribution of Actual and Predicted Values
plt.figure(figsize=(12, 6))
sns.kdeplot(y_regression_test, label='Actual Sales Volume', fill=True)
sns.kdeplot(y_regression_pred, label='Predicted Sales Volume', fill=True)
plt.xlabel("Sales Volume")
plt.ylabel("Density")
plt.title("Distribution of Actual and Predicted Sales Volume")
plt.legend()
plt.show()

# 4. Parity Plot
plt.figure(figsize=(8, 8))
plt.scatter(y_regression_test, y_regression_pred, alpha=0.5)
plt.plot([y_regression_test.min(), y_regression_test.max()], [y_regression_test.min(), y_regression_test.max()], 'k--', lw=2)
plt.xlabel("Actual Sales Volume")
plt.ylabel("Predicted Sales Volume")
plt.title("Parity Plot (Actual vs Predicted)")
plt.show()

# 4. Gaussian Process Classification
# Define Sales Categories
# Create a binary or multi-class variable from 'sales_volume'
# Define thresholds for sales categories
low_sales_threshold = data['sales_volume'].quantile(0.33)
high_sales_threshold = data['sales_volume'].quantile(0.66)

# Create a function to categorize sales volume
def categorize_sales(sales):
    if sales <= low_sales_threshold:
        return 'Low Sales'
    elif sales <= high_sales_threshold:
        return 'Medium Sales'
    else:
        return 'High Sales'

# Apply the categorization function to create the 'sales_category' column
data['sales_category'] = data['sales_volume'].apply(categorize_sales)

# Feature Selection
# Choose input features for classification
classification_features = ['product_price', 'product_star_rating', 'product_num_ratings', 'price_discount', 'delivery_time']

# Convert multiclass to binary.
y_classification_binary = data['sales_category'].apply(lambda x: 1 if x == 'High Sales' else 0)
X_classification_train, X_classification_test, y_classification_train_binary, y_classification_test_binary = train_test_split(data[classification_features], y_classification_binary, test_size=0.2, random_state=42)

# Define a kernel
kernel = RBF(length_scale=1.0, length_scale_bounds=(1e-1, 10.0))

# Create a GaussianProcessClassifier object with the chosen kernel
gp_classifier = GaussianProcessClassifier(kernel=kernel, n_restarts_optimizer=10)

# Train the model
gp_classifier.fit(X_classification_train, y_classification_train_binary)

# Prediction and Evaluation
# Predict sales category on the testing set
y_classification_pred = gp_classifier.predict(X_classification_test)

# Evaluate the model
accuracy = accuracy_score(y_classification_test_binary, y_classification_pred)
precision = precision_score(y_classification_test_binary, y_classification_pred, average='weighted')
recall = recall_score(y_classification_test_binary, y_classification_pred, average='weighted')
f1 = f1_score(y_classification_test_binary, y_classification_pred, average='weighted')
confusion = confusion_matrix(y_classification_test_binary, y_classification_pred)

print("\nGaussian Process Classification Results:")
print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1-score:", f1)
print("Confusion Matrix:\n", confusion)

# Classification Plots
# 1. Decision Boundary Plot (Requires 2D data for easy visualization)
# For simplicity, let's use just two features: 'product_price' and 'product_star_rating'
X_classification_2d = data[['product_price', 'product_star_rating']].values
y_classification_binary = data['sales_category'].apply(lambda x: 1 if x == 'High Sales' else 0).values
X_train_2d, X_test_2d, y_train_2d, y_test_2d = train_test_split(X_classification_2d, y_classification_binary, test_size=0.2, random_state=42)

# Train a new classifier with only two features
gp_classifier_2d = GaussianProcessClassifier(kernel=kernel, n_restarts_optimizer=10)
gp_classifier_2d.fit(X_train_2d, y_train_2d)

# Create a mesh grid
h = .02  # step size in the mesh
x_min, x_max = X_classification_2d[:, 0].min() - 1, X_classification_2d[:, 0].max() + 1
y_min, y_max = X_classification_2d[:, 1].min() - 1, X_classification_2d[:, 1].max() + 1
xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))

# Obtain predictions for each point in the mesh grid
Z = gp_classifier_2d.predict(np.c_[xx.ravel(), yy.ravel()])
Z = Z.reshape(xx.shape)

# Plot the decision boundary
plt.figure(figsize=(8, 6))
plt.contourf(xx, yy, Z, cmap=plt.cm.RdBu, alpha=0.8)

# Plot the training points
plt.scatter(X_train_2d[:, 0], X_train_2d[:, 1], c=y_train_2d, cmap=plt.cm.RdBu, edgecolors='k')
plt.xlabel("Product Price")
plt.ylabel("Product Star Rating")
plt.title("Gaussian Process Classification: Decision Boundary (2D)")
plt.show()

# 2. Bar plot of predicted class probabilities
# Get predicted probabilities for test data
y_prob = gp_classifier.predict_proba(X_classification_test)

# Choose a random sample from the test set to plot
sample_index = np.random.randint(0, len(X_classification_test))
sample_probabilities = y_prob[sample_index]

# Create a bar plot
plt.figure(figsize=(8, 6))
plt.bar(['Not High Sales', 'High Sales'], sample_probabilities)
plt.xlabel("Class")
plt.ylabel("Probability")
plt.title(f"Predicted Class Probabilities for Sample {sample_index}")
plt.ylim([0, 1])
plt.show()

# 3. Class Distribution Plot
plt.figure(figsize=(8, 6))
sns.countplot(x=y_classification_test_binary)
plt.title("Distribution of Classes in Test Set")
plt.xlabel("Class (0: Not High Sales, 1: High Sales)")
plt.ylabel("Number of Samples")
plt.show()

# 4. ROC Curve
y_probabilities = gp_classifier.predict_proba(X_classification_test)[:, 1]
fpr, tpr, thresholds = roc_curve(y_classification_test_binary, y_probabilities)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC)')
plt.legend(loc="lower right")
plt.show()

print("AUC:", roc_auc)

# Classification: Confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(confusion, annot=True, fmt="d", cmap="Blues",
            xticklabels=['Not High Sales', 'High Sales'],
            yticklabels=['Not High Sales', 'High Sales'])
plt.xlabel("Predicted Category")
plt.ylabel("Actual Category")
plt.title("Confusion Matrix (Gaussian Process Classification)")
plt.show()

